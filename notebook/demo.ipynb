{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration notebook for the mailcom package\n",
    "*Scientific Software Center, University of Heidelberg, December 2024*\n",
    "The `mailcom` package is used to anonymize/pseudonymize textual data, i.e. email content. It takes an `eml` or `html` file as input and extracts information about attachements, number of attachements and type, and the content of the email body. The latter is then parsed through [`spaCy`](https://spacy.io/) and divided into sentences. The sentences are fed to a [`transformers`](https://huggingface.co/docs/transformers/en/index) named entity recognition (NER) [pipeline](https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/pipelines), and person names, places, organizations, miscellaneous, are detected in the inference task. Names are replaced by pseudos, while locations, organizations and miscellaneous are replaced by `[location]`, `[organization]` and `[misc]`. The text is further parsed using string methods, to replace any numbers with `[number]` and email addresses with `[email]`. The processed text and metadata can then be written to an `xml` file or into a pandas dataframe.\n",
    "\n",
    "Please note that 100% accuracy is not possible with this task. Any output needs to be further checked by a human to ensure the text has been anonymized completely.\n",
    "\n",
    "The current set-up is for Romance languages, however [other language models](https://spacy.io/usage/models) can also be loaded into the spaCy pipeline. The transformers pipeline uses the `xlm-roberta-large-finetuned-conll03-english` model revision number `18f95e9` by default, but other models can also be passed (see below).\n",
    "\n",
    "Before using the `mailcom` package, please install it into your conda environment using\n",
    "```\n",
    "pip install mailcom\n",
    "```\n",
    "After that, select the appropriate kernel for your Jupyter notebook and execute the cell below to import the package. The package is currently under active development and any function calls are subject to changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailcom.inout\n",
    "import mailcom.parse\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a function used to display the result in the end, and highlight all named entities found in the text. It is used for demonstration purposes in this example.\n",
    "\n",
    "Generally, this is a simple approach at highlighting the replaced pseudonyms, but the method itself is prone to errors and should only be used with care when assessing if the text has been anonymized correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary matching colors to the different entity types\n",
    "colors = {\n",
    "    \"LOC\": \"green\",\n",
    "    \"ORG\": \"blue\",\n",
    "    \"MISC\": \"yellow\",\n",
    "    \"PER\": \"red\"\n",
    "}\n",
    "\n",
    "# function for displaying the result using HTML\n",
    "def highlight_ne(text, ne_list):\n",
    "    # create a list of all entities with their positions\n",
    "    entities = []\n",
    "    for ne in ne_list:\n",
    "        # avoid substituting the same entity multiple times\n",
    "        if ne[\"word\"] not in entities and ne[\"entity_group\"] in colors:\n",
    "            entities.append((ne, colors.get(ne[\"entity_group\"])))\n",
    "    \n",
    "    # sort entities by their positions in the text in reverse order\n",
    "    # is this necessary?\n",
    "    # entities = sorted(entities, key=lambda x: x[0][\"start\"], reverse=True)\n",
    "\n",
    "    # replace all \"<\" and \">\" which may mess up spans\n",
    "    text = text.replace(\"<\", \"&lt;\")\n",
    "    text = text.replace(\">\", \"&gt;\")\n",
    "    # replace entities with highlighted spans\n",
    "    for entity, color in entities:\n",
    "        ent_word = entity[\"word\"]\n",
    "        # I think it may be overwriting the already replaced ones\n",
    "        # Instead, maybe sort which ones are different and not a subset?\n",
    "        text = text.replace(ent_word, f\"<span style=\\\"background-color:{color}\\\">{ent_word}</span>\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the input files are loaded from the given `input_dir` directory. You can provide relative or absolute paths to the directory that contains your `eml` or `html` files. All files of the `eml` or `html` file type in that directory will be considered input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files from input_dir - change this to your own directory\n",
    "input_dir = \"../data/in/test\"\n",
    "\n",
    "io = mailcom.inout.InoutHandler(directory_name = input_dir)\n",
    "\n",
    "# some internal processing\n",
    "io.list_of_files()\n",
    "# extracts the text of all emails in the directory and cleans up html content\n",
    "io.process_emails()\n",
    "\n",
    "# create pseudonymization object and load spacy and transformers\n",
    "# set the spacy language for sentence splitting\n",
    "spacy_language = \"fr\"\n",
    "# you may also set the model using `model = \"fr_core_news_md\"`\n",
    "spacy_model = \"default\"\n",
    "# set the model for transformers, here using the default model\n",
    "transformers_model = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "# set the revision number for transformers, here using the default revision number\n",
    "transformers_revision_number = \"18f95e9\"\n",
    "ps = mailcom.parse.Pseudonymize()\n",
    "ps.init_spacy(language=spacy_language, model=spacy_model)\n",
    "ps.init_transformers(model=transformers_model, model_revision_number=transformers_revision_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the emails are looped over and the text is extracted. The text is then split into sentences and the sentences are pseudonymized. The pseudonymized sentences are then joined back into a text and saved to a new file.\n",
    "\n",
    "The input text is displayed and the found named entities are highlighted for demonstration. Note that emails (all words containing '@') are filtered out seperately and thus not highlighted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over mails and pseudonymize them\n",
    "for _, email in enumerate(io.get_email_list()):\n",
    "    # the email text and metadata are stored in a dict\n",
    "    # the dict already has the entries content, date, attachments, attachment type\n",
    "    if not email[\"content\"]:\n",
    "        continue\n",
    "    # Test functionality of Pseudonymize class\n",
    "    # The output text is returned, as well as saved as a dict entry as \"pseudo_content\"\n",
    "    _ = ps.pseudonymize(email)\n",
    "\n",
    "    # display original text and highlight found and replaced NEs\n",
    "    highlighted_html = highlight_ne(email[\"content\"], ps.ne_list)\n",
    "    display(HTML(highlighted_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the output can be written to a file or processed further. The output is a list of dictionaries, each containing the metadata of the email and the pseudonymized content. In the below cell, the output is saved in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to pandas df\n",
    "df = pd.DataFrame(io.get_email_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output can be saved as a csv file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.write_csv(\"../data/out/out_demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mailcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
