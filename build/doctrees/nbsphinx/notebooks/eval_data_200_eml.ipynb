{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook for creating eval. data from Corpus 200 emails\n",
    "*Scientific Software Center, University of Heidelberg, April 2025*\n",
    "\n",
    "The dataset `Corpus 200 emails` contains 200 multilingual emails (Spanish, English, and Portuguese/Galician) formatted in accordance with the RFC2822 specification. Download the dataset [here](https://figshare.com/articles/dataset/Corpus_200_Emails/1326662?file=1936502)\n",
    "\n",
    "This notebook will create an evaluation dataset for `mailcom` using 30 emails from `Corpus 200 emails` (10 emails per language).\n",
    "\n",
    "For each email in the dataset, we record:\n",
    "* email content\n",
    "* email language\n",
    "* detected dates in the email\n",
    "* list of named entities (NE)\n",
    "* pseudo content\n",
    "* list of sentences\n",
    "* list of sentences after email pseudonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "To run the notebook in one go, toggle the following sections to collapse their cells:\n",
    "* `General settings`\n",
    "* `Copy files (run once)`\n",
    "* `Create a drafe version of the datset (run once)`\n",
    "* `Manually check and modify each email`\n",
    "\n",
    "Then run all cells in each section at once.\n",
    "\n",
    "All `csv` files are created under `\"../../../data/\"`, including:\n",
    "* parse results obtained using `mailcom` (`eval_data_200_eml.csv`)\n",
    "* updated data for each `eml` file (`eval_data_200_eml_idx{i}.csv` with `i` $\\in [0..num\\_of\\_files)$)\n",
    "* concatenated `csv` of updated data for all `eml` files (`checked_eval_data_200_eml_{num_of_files}_emails.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark email numbers for languages\n",
    "# start with 1\n",
    "gl_emails = [\"01\", \"02\", \"03\", \"04\", 10, 12, 15]\n",
    "gl_files = [str(i) + \".eml\" for i in gl_emails]\n",
    "pt_emails = [30, 36, 66] # 30 is pt accoring to Google Translate but it is actually es\n",
    "pt_files = [str(i) + \".eml\" for i in pt_emails]\n",
    "es_emails = [\"05\", \"06\", \"07\", \"09\", 11, 23, 28, 31, 33, 34]\n",
    "es_files = [str(i) + \".eml\" for i in es_emails]\n",
    "en_emails = [13, 14, 19, 20, 22, 24, 32, 35, 37, 38]\n",
    "en_files = [str(i) + \".eml\" for i in en_emails]\n",
    "chosen_files = gl_files + pt_files + es_files + en_files\n",
    "assert len(set(chosen_files)) == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../../../eval_data_mailcom\"\n",
    "input_dir = \"../../../mailcom/test/data_extended/200_eml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_group = \"MISC\"\n",
    "misc_pseudo = \"[misc]\"\n",
    "org_group = \"ORG\"\n",
    "org_pseudo = \"[organization]\"\n",
    "loc_group = \"LOC\"\n",
    "loc_pseudo = \"[location]\"\n",
    "\n",
    "# repeated words, SonarQube\n",
    "repeated_words = [\"Expert Systems With Applications\", \n",
    "                  \"Expert Systems with Applications\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Copy files (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run when needed!\n",
    "# copy files from source to input_dir\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "source_files = Path(source_dir).glob(\"*.eml\")\n",
    "for source_file in source_files:\n",
    "    if source_file.name in chosen_files:\n",
    "        shutil.copy(source_file, input_dir)\n",
    "        print(f\"Copied {source_file.name} to {input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Create a draft version of the dataset (run once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "First, we use the language detection, date detection, and pseunonymize from `mailcom` to buil the draft version of the dataset. Each email will be manually checked for validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate language detection\n",
    "new_settings = {\"default_lang\": \"\"}\n",
    "workflow_settings = mailcom.get_workflow_settings(new_settings=new_settings, \n",
    "                                                  save_updated_settings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files from input_dir\n",
    "input_handler = mailcom.get_input_handler(in_path=input_dir, in_type=\"dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the input data\n",
    "mailcom.process_data(input_handler.get_email_list(), workflow_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to csv\n",
    "mailcom.write_output_data(input_handler, \"../../../data/eval_data_200_eml.csv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Manually check and modify each email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary functions\n",
    "\n",
    "import pandas as pd\n",
    "import mailcom\n",
    "from mailcom.parse import Pseudonymize\n",
    "\n",
    "\n",
    "# get workflow settings\n",
    "new_settings = {\"default_lang\": \"\"}\n",
    "workflow_settings = mailcom.get_workflow_settings(new_settings=new_settings, \n",
    "                                                  save_updated_settings=False)\n",
    "pseudonymizer = Pseudonymize(workflow_settings.get(\"pseudo_first_names\", {}))\n",
    "\n",
    "\n",
    "def print_email(email: dict):\n",
    "    print(\"file name:\", email[\"file_name\"])\n",
    "    print(\"= Email cleaned content =======\\n\", email[\"cleaned_content\"])\n",
    "    print(\"= Email language =======\\n\", email[\"lang\"])\n",
    "    print(\"= Detected dates =======\\n\", email[\"detected_datetime\"])\n",
    "    print(\"= NE list =======\")\n",
    "    for idx, (sent_idx, ne) in enumerate(zip(eval(email[\"ne_sent\"]), eval(email[\"ne_list\"]))):\n",
    "        print(f\"  {idx}- sentence {sent_idx}, {ne[\"word\"]} - {ne[\"entity_group\"]} - {ne[\"start\"]} - {ne[\"end\"]} - {ne[\"pseudonym\"]}\")\n",
    "    print(\"= Sentences =======\\n\")\n",
    "    for i, sent in enumerate(eval(email[\"sentences\"])):\n",
    "        print(f\"  {i}- {sent}\")\n",
    "    print(\"= Pseudo content =======\\n\", email[\"pseudo_content\"])\n",
    "\n",
    "\n",
    "def check_email_lang(file_name, lang) -> bool:\n",
    "    if file_name in gl_files and lang == \"gl\":\n",
    "        return True\n",
    "    elif file_name in pt_files and lang == \"pt\":\n",
    "        return True\n",
    "    elif file_name in es_files and lang == \"es\":\n",
    "        return True\n",
    "    elif file_name in en_files and lang == \"en\":\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Incorrect detected language for file:\", file_name)\n",
    "        return False\n",
    "\n",
    "\n",
    "def find_left_offset(old_word, new_word):\n",
    "    old_longer = len(old_word) > len(new_word)\n",
    "    # find old word in the new word\n",
    "    if old_longer:\n",
    "        start_offset = old_word.find(new_word)\n",
    "    else:\n",
    "        start_offset = new_word.find(old_word)\n",
    "\n",
    "    left_offset = start_offset if old_longer else - start_offset\n",
    "    return left_offset\n",
    "\n",
    "\n",
    "def update_ne_word(item_idx, new_word, ne_list):\n",
    "    old_word = ne_list[item_idx][\"word\"]\n",
    "    ne_list[item_idx][\"word\"] = new_word\n",
    "    l_offset = find_left_offset(old_word, ne_list[item_idx][\"word\"])\n",
    "    ne_list[item_idx][\"start\"] += l_offset\n",
    "    ne_list[item_idx][\"end\"] = ne_list[item_idx][\"start\"] + len(ne_list[item_idx][\"word\"])\n",
    "\n",
    "\n",
    "def update_ne_group(item_idx, new_group, new_pseudo, ne_list):\n",
    "    ne_list[item_idx][\"entity_group\"] = new_group\n",
    "    ne_list[item_idx][\"pseudonym\"] = new_pseudo\n",
    "\n",
    "\n",
    "def remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices):\n",
    "    new_ne_list = []\n",
    "    new_ne_sent = []\n",
    "    for idx, ne in enumerate(ne_list):\n",
    "        if idx in incorrect_ne_indices:\n",
    "            # remove the ne from the list\n",
    "            continue\n",
    "        else:\n",
    "            new_ne_list.append(ne)\n",
    "            new_ne_sent.append(ne_sent[idx])\n",
    "    return new_ne_list, new_ne_sent\n",
    "\n",
    "\n",
    "def find_nth_occurrence(sentence, word, occurrence):\n",
    "    import re\n",
    "    pattern = re.compile(re.escape(word))\n",
    "    matches = [m.start() for m in pattern.finditer(sentence)]\n",
    "    return matches[occurrence - 1] if len(matches) >= occurrence else -1\n",
    "\n",
    "\n",
    "def add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_e_group, sentence, ocurrence, ne_list, ne_sent):\n",
    "    new_ne = {\"entity_group\": n_e_group, \"word\": n_word, \"pseudonym\": n_pseudonym}\n",
    "    # important!\n",
    "    # indices are determined after email pseudonymization!\n",
    "    sentence = pseudonymizer.pseudonymize_email_addresses(sentence)\n",
    "    # find the start and end of the new ne\n",
    "    new_ne[\"start\"] = find_nth_occurrence(sentence, n_word, ocurrence)\n",
    "    new_ne[\"end\"] = new_ne[\"start\"] + len(new_ne[\"word\"])\n",
    "    ne_list.insert(insert_idx, new_ne)\n",
    "    ne_sent.insert(insert_idx, sent_idx)\n",
    "\n",
    "\n",
    "def get_new_pseudo_content(df, row_idx):\n",
    "    # get updated values\n",
    "    email = df.iloc[row_idx]\n",
    "\n",
    "    # get NE for each sentence in the email\n",
    "    ne_sent_dict = {}\n",
    "    for sent_idx, ne in zip(email[\"ne_sent\"], email[\"ne_list\"]):\n",
    "        if str(sent_idx) not in ne_sent_dict:\n",
    "            ne_sent_dict[str(sent_idx)] = []\n",
    "        ne_sent_dict[str(sent_idx)].append(ne)\n",
    "\n",
    "    # note. the indices of NE are only correct after the email is pseudonymized!\n",
    "    updated_pseudo_content = pseudonymizer.pseudonymize_with_updated_ne(eval(email[\"sentences_after_email\"]),\n",
    "                                                                        ne_sent_dict,\n",
    "                                                                        email[\"lang\"],\n",
    "                                                                        eval(email[\"detected_datetime\"]),\n",
    "                                                                        workflow_settings.get(\"pseudo_emailaddresses\", True),\n",
    "                                                                        workflow_settings.get(\"pseudo_ne\", True),\n",
    "                                                                        workflow_settings.get(\"pseudo_numbers\", True))\n",
    "    return updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the original csv\n",
    "df = pd.read_csv(\"../../../data/eval_data_200_eml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark incorrect indices of NE -- compared to the original\n",
    "incorrect_ne_indices = {}\n",
    "incorrect_ne_indices[\"0\"] = {\"u\": [2]}\n",
    "incorrect_ne_indices[\"1\"] = {\"u\": [4],\n",
    "                             \"r\": [7],\n",
    "                             \"a\": [2]} # the \"r\" and \"a\" cases are updated manually\n",
    "incorrect_ne_indices[\"2\"] = {\"u\": [2]}\n",
    "incorrect_ne_indices[\"3\"] = {\"u\": [1],\n",
    "                             \"r\": [3]}\n",
    "incorrect_ne_indices[\"4\"] = {\"u\": [6, 8, 9],\n",
    "                             \"r\": [10],\n",
    "                             \"a\": [6, 4, 5]}\n",
    "incorrect_ne_indices[\"5\"] = {\"u\": [9]}\n",
    "incorrect_ne_indices[\"6\"] = {\"u\": [6],\n",
    "                             \"r\": [5],\n",
    "                             \"a\": [2]}\n",
    "incorrect_ne_indices[\"7\"] = {\"a\": [22],\n",
    "                             \"r\": [10, 11]}\n",
    "incorrect_ne_indices[\"8\"] = {\"u\": [1, 4, 5, 6 ,7, 9, 10, 15, 20, 22, 27],\n",
    "                             \"r\": [23, 31],\n",
    "                             \"a\": [8],\n",
    "                             \"r-c\": [2, 3]}\n",
    "incorrect_ne_indices[\"9\"] = {\"u\": [17]}\n",
    "incorrect_ne_indices[\"10\"] = {\"u\": [1, 19],\n",
    "                              \"r\": [13, 20, 23]}\n",
    "incorrect_ne_indices[\"11\"] = {\"u\": [6, 9, 11, 13, 18, 20, 21],\n",
    "                              \"a\": [25],\n",
    "                              \"r\": [24],\n",
    "                              \"a-c\": [12, 7],\n",
    "                              \"r-c\": [5],\n",
    "                              \"a-c-c\": [4, 2, 1]}\n",
    "incorrect_ne_indices[\"12\"] = {\"u\": [0, 5],\n",
    "                              \"a\": [8, 9],\n",
    "                              \"r\": [6],\n",
    "                              \"a-c\": [1, 0]}\n",
    "incorrect_ne_indices[\"13\"] = {\"r\": [3]}\n",
    "incorrect_ne_indices[\"14\"] = {\"u\": [4, 10],\n",
    "                              \"r\": [11, 6],\n",
    "                              \"a\": [2, 1]}\n",
    "incorrect_ne_indices[\"15\"] = {\"u\": [11, 13],\n",
    "                              \"r\": [12, 14],\n",
    "                              \"a\": [3, 3]}\n",
    "incorrect_ne_indices[\"16\"] = {\"u\": [9, 16, 28, 40, 42, 44, 45, 51, 52, 55, 81, 82, 84, 87, 88],\n",
    "                              \"r\": [89],\n",
    "                              \"a\": [88, 88, 60, 58, 56, 56, 55, 53, 51, 41, 41, 40, 40],\n",
    "                              \"r-c\": [22, 13],\n",
    "                              \"a-c\": [10, 4]}\n",
    "incorrect_ne_indices[\"17\"] = {\"u\": [6, 11, 26, 30, 33, 35, 36, 39, 41],\n",
    "                              \"r\": [37, 34, 27, 9, 7]}\n",
    "incorrect_ne_indices[\"18\"] = {\"u\": [9],\n",
    "                              \"a\": [13, 13, 9]}\n",
    "incorrect_ne_indices[\"19\"] = {\"u\": [3],\n",
    "                              \"a\": [3]}\n",
    "incorrect_ne_indices[\"20\"] = {\"u\": [1, 2],\n",
    "                              \"a\": [4, 1, 1]}\n",
    "incorrect_ne_indices[\"21\"] = {\"u\": [1, 2]}\n",
    "incorrect_ne_indices[\"22\"] = {\"u\": [4, 6, 9, 10, 24, 25, 26, 27, 28, 29, 31],\n",
    "                              \"r\": [33, 22, 14, 12, 8]}\n",
    "incorrect_ne_indices[\"23\"] = {\"u\": [2, 5, 8, 9, 11, 14],\n",
    "                              \"r\": [1, 3, 6, 7, 12, 13, 16]}\n",
    "incorrect_ne_indices[\"24\"] = {\"u\": [0, 1, 3, 7, 9, 11, 13, 15, 17, 19, 21, 22, 23, 25, 27, 29, 38, 51, 54, 55, 57, 59],\n",
    "                              \"r\": [60, 58, 41, 39, 35],\n",
    "                              \"a\": [35],\n",
    "                              \"r-c\": [30, 28, 26, 24, 18, 16, 14, 12, 10]}\n",
    "incorrect_ne_indices[\"25\"] = {\"u\": [1, 2, 6],\n",
    "                              \"r\": [5, 4],\n",
    "                              \"a\": [3, 2]}\n",
    "incorrect_ne_indices[\"26\"] = {\"u\": [4],\n",
    "                              \"r\": [12],\n",
    "                              \"a\": [9],\n",
    "                              \"r-c\": [8],\n",
    "                              \"a-c\": [7],\n",
    "                              \"r-c-c\": [6, 5, 3]}\n",
    "incorrect_ne_indices[\"27\"] = {}\n",
    "incorrect_ne_indices[\"28\"] = {\"u\": [2, 3, 8, 11, 12],\n",
    "                              \"r\": [13]}\n",
    "incorrect_ne_indices[\"29\"] = {\"u\": [1, 3],\n",
    "                              \"a\": [4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Row idx 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 2\n",
    "new_word = \"Galiza\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email dict\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "##### Row idx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 1\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 4\n",
    "new_word = \"Proxecto Fin de Carreira\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 2\n",
    "sent_idx = 0\n",
    "n_word = \"Sala de Xuntas\"\n",
    "n_pseudonym = loc_pseudo\n",
    "n_entity_group = loc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "##### Row idx 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 2\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 2\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "##### Row idx 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 3\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "##### Row idx 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 4\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 6\n",
    "new_word = \"SPEA\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 8\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "new_word = \"SPEA2\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 6\n",
    "sent_idx = 4\n",
    "n_word = \"NSGAII\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 4\n",
    "sent_idx = 2\n",
    "n_word = \"NSGAII\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 5\n",
    "sent_idx = 2\n",
    "n_word = \"SPEA2\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "##### Row idx 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 5\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 9\n",
    "new_word = \"Gabinete Juridico\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "##### Row idx 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 6\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 6\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 2\n",
    "sent_idx = 1\n",
    "n_word = \"ees\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "##### Row idx 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 7\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 22\n",
    "sent_idx = 11\n",
    "n_word = \"Estatuto\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any\n",
    "df.at[row_idx, \"detected_datetime\"] = [\"07 de mayo de 2013 12:52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "##### Row idx 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 8\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "new_word = \"Enxeñería Informática\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 4\n",
    "new_word = \"Campus de Ourense\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 5\n",
    "new_word = \"nasassocialmedia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 6\n",
    "new_word = \"Enxeñaría Informática\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 7\n",
    "new_word = \"Enxeñaría Informática\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "new_word = \"nasassocialmedia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 10\n",
    "new_word = \"nasassocialmedia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 15\n",
    "new_word = \"Campus de Ourense\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 20\n",
    "new_word = \"nasassocialmedia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 22\n",
    "new_word = \"nasassocialmedia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 27\n",
    "new_word = \"Edificio Politécnico\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 8\n",
    "sent_idx = 3\n",
    "n_word = \"LRU\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group, \n",
    "            eval(email[\"sentences\"])[sent_idx], 1, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "##### Row idx 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 9\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 17\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "##### Row idx 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 10\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "new_word = repeated_words[0]\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 19\n",
    "new_word = \"OX5 1GB\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "##### Row idx 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 11\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 6\n",
    "new_word = \"eswa\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 11\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 13\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 18\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 20\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 21\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 25\n",
    "sent_idx = 21\n",
    "n_word = repeated_words[0]\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 12\n",
    "sent_idx = 12\n",
    "n_word = \"EES\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 7\n",
    "sent_idx = 6\n",
    "n_word = \"ees\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 2\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 4\n",
    "sent_idx = 6\n",
    "n_word = \"ees\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 2\n",
    "sent_idx = 3\n",
    "n_word = repeated_words[0]\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 2\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 1\n",
    "sent_idx = 3\n",
    "n_word = repeated_words[0]\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "##### Row idx 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 12\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 0\n",
    "new_word = \"Organización Académica, Profesorado e Titulacións\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 5\n",
    "new_word = \"Ingeniería Informática\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 8\n",
    "sent_idx = 1\n",
    "n_word = \"Vicerrectoría\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 9\n",
    "sent_idx = 1\n",
    "n_word = \"Organización Académica, Profesorado e Titulacións\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 1\n",
    "sent_idx = 0\n",
    "n_word = \"Reitoría\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 0\n",
    "sent_idx = 0\n",
    "n_word = \"Vicerreitoría\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "##### Row idx 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 13\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "##### Row idx 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 14\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 4\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 10\n",
    "new_word = \"Igrexa de Santa Eufemia\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 2\n",
    "sent_idx = 0\n",
    "n_word = \"Edificio de Facultades\"\n",
    "n_pseudonym = loc_pseudo\n",
    "n_entity_group = loc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 1\n",
    "sent_idx = 0\n",
    "n_word = \"Vicerreitoría\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "##### Row idx 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 15\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 11\n",
    "new_word = \"Fundación Empresa  Universidad Gallega FEUGA\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 13\n",
    "new_word = \"Rúa Lope Gómez de Marzoa\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 3\n",
    "sent_idx = 3\n",
    "n_word = \"local A9\"\n",
    "n_pseudonym = loc_pseudo\n",
    "n_entity_group = loc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "\n",
    "insert_idx = 3\n",
    "sent_idx = 3\n",
    "n_word = \"Área Comercial\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "##### Row idx 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 16\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 9\n",
    "new_word = \"International Office\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 16\n",
    "new_word = \"ERASMUS\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 28\n",
    "new_word = \"Alemán\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 40\n",
    "new_word = \"Testdaf\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 42\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 44\n",
    "new_word = \"Francés\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 45\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 51\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "item_idx = 52\n",
    "update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "item_idx = 55\n",
    "new_word = \"FIRST Cambridge\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 81\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 82\n",
    "new_word = \"bubela\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 84\n",
    "new_word = \"bubela\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 87\n",
    "new_word = \"uvigo\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 88\n",
    "new_word = \"uvigo\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 88\n",
    "sent_idx = 21\n",
    "n_word = \"facebook\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 88\n",
    "sent_idx = 21\n",
    "n_word = \"Facebook\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 60\n",
    "sent_idx = 17\n",
    "n_word = \"francés\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 58\n",
    "sent_idx = 17\n",
    "n_word = \"Bulats\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 2\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 56\n",
    "sent_idx = 17\n",
    "n_word = \"ISE II\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 56\n",
    "sent_idx = 17\n",
    "n_word = \"Trinity\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 55\n",
    "sent_idx = 17\n",
    "n_word = \"Bulats\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 53\n",
    "sent_idx = 16\n",
    "n_word = \"DELF\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "\n",
    "insert_idx = 51\n",
    "sent_idx = 15\n",
    "n_word = \"TCF\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 41\n",
    "sent_idx = 13\n",
    "n_word = \"TDN\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 41\n",
    "sent_idx = 13\n",
    "n_word = \"Niveaustufe\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 40\n",
    "sent_idx = 13\n",
    "n_word = \"ISE I\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 40\n",
    "sent_idx = 13\n",
    "n_word = \"Trinity\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 10\n",
    "sent_idx = 3\n",
    "n_word = \"Oficina de Relacións Internacionais\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 4\n",
    "sent_idx = 1\n",
    "n_word = \"alemana\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any\n",
    "df.at[row_idx, \"detected_datetime\"] = [\"08 de enero de 2013 11:11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173",
   "metadata": {},
   "source": [
    "##### Row idx 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 17\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 6\n",
    "new_word = \"dcai\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 11\n",
    "new_word = \"Scientific Committee\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 26\n",
    "new_word = \"José M. Molina\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 30\n",
    "update_ne_group(item_idx, \"PER\", \"Arlo\", ne_list)\n",
    "\n",
    "item_idx = 33\n",
    "new_word = \"Andre Ponce de Leon F. de Carvalho\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Adri\", ne_list)\n",
    "\n",
    "item_idx = 35\n",
    "new_word = \"University of Sao Paulo\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 36\n",
    "new_word = \"Sao Carlos\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 39\n",
    "update_ne_group(item_idx, \"PER\", \"Marce\", ne_list)\n",
    "\n",
    "item_idx = 41\n",
    "new_word = \"dcai\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182",
   "metadata": {},
   "source": [
    "##### Row idx 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 18\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 9\n",
    "new_word = \"Scatter Search\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 13\n",
    "sent_idx = 12\n",
    "n_word = \"GDV\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 2\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 13\n",
    "sent_idx = 12\n",
    "n_word = \"GDV\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 9\n",
    "sent_idx = 11\n",
    "n_word = \"EMOA\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191",
   "metadata": {},
   "source": [
    "##### Row idx 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 19\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 3\n",
    "new_word = \"Escuela Superior de Ingeniería Informática\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 3\n",
    "sent_idx = 4\n",
    "n_word = \"Celso Campos\"\n",
    "n_pseudonym = \"José\"\n",
    "n_entity_group = \"PER\"\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "##### Row idx 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 20\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 2\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 4\n",
    "sent_idx = 6\n",
    "n_word = \"PDA\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 1\n",
    "sent_idx = 1\n",
    "n_word = \"POD\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 1\n",
    "sent_idx = 1\n",
    "n_word = \"PDA\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209",
   "metadata": {},
   "source": [
    "##### Row idx 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 21\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "new_word = \"Accessibles\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 2\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218",
   "metadata": {},
   "source": [
    "##### Row idx 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 22\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 4\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 6\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 10\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "for item_idx in [24, 25, 26, 27, 28]:\n",
    "    update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "\n",
    "item_idx = 29\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 31\n",
    "new_word = \"Information Sciences\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227",
   "metadata": {},
   "source": [
    "##### Row idx 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 23\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 2\n",
    "new_word = \"José Ramón Méndez Reboredo\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 5\n",
    "new_word = \"Campus As Lagoas S/N\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 8\n",
    "new_word = \"OurenseOurenseEspaña Península\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "new_word = \"José Ramón Méndez Reboredo\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"José\", ne_list)\n",
    "\n",
    "item_idx = 11\n",
    "new_word = \"Campus As Lagoas S/N\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 14\n",
    "new_word = \"OurenseOurenseEspaña Península\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236",
   "metadata": {},
   "source": [
    "##### Row idx 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 24\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 0\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 1\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 3\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 7\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 9\n",
    "new_word = \"Méndez, J.R.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 11\n",
    "new_word = \"Glez-Peña, D.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Alex\", ne_list)\n",
    "\n",
    "item_idx = 13\n",
    "new_word = \"Fdez-Riverola, F.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Ariel\", ne_list)\n",
    "\n",
    "item_idx = 15\n",
    "new_word = \"Díaz, F.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Cruz\", ne_list)\n",
    "\n",
    "item_idx = 17\n",
    "new_word = \"Corchado, J.M.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Fran\", ne_list)\n",
    "\n",
    "item_idx = 19\n",
    "new_word = repeated_words[1]\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 21\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 22\n",
    "update_ne_group(item_idx, \"PER\", \"Angel\", ne_list)\n",
    "\n",
    "item_idx = 23\n",
    "new_word = \"Reboiro-Jato, M.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Adri\", ne_list)\n",
    "\n",
    "item_idx = 25\n",
    "new_word = \"Díaz, F.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Cruz\", ne_list)\n",
    "\n",
    "item_idx = 27\n",
    "new_word = \"Díaz, E.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Mati\", ne_list)\n",
    "\n",
    "item_idx = 29\n",
    "new_word = \"Fdez-Riverola, F.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, \"PER\", \"Ariel\", ne_list)\n",
    "\n",
    "item_idx = 38\n",
    "new_word = \"Elsevier B.V.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 51\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 54\n",
    "new_word = \"elsevier\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 55\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 57\n",
    "new_word = \"Scopus\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 59\n",
    "new_word = \"Elsevier B.V.\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 35\n",
    "sent_idx = 5\n",
    "n_word = \"CiteAlert\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245",
   "metadata": {},
   "source": [
    "##### Row idx 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 25\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "new_word = \"SAI\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 2\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 6\n",
    "update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 3\n",
    "sent_idx = 1\n",
    "n_word = \"ciencias experimentais\"\n",
    "n_pseudonym = loc_pseudo\n",
    "n_entity_group = loc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "insert_idx = 2\n",
    "sent_idx = 0\n",
    "n_word = \"Ciencias del Mar y Bioloxía\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254",
   "metadata": {},
   "source": [
    "##### Row idx 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 26\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 4\n",
    "new_word = \"Elsevier Editorial System\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 9\n",
    "sent_idx = 15\n",
    "n_word = \"PDF\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 7\n",
    "sent_idx = 6\n",
    "n_word = \"ees\"\n",
    "n_pseudonym = misc_pseudo\n",
    "n_entity_group = misc_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c-c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263",
   "metadata": {},
   "source": [
    "##### Row idx 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 27\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272",
   "metadata": {},
   "source": [
    "##### Row idx 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 28\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 2\n",
    "new_word = \"Lei Orgánica\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 3\n",
    "new_word = \"Protección de datos de carácter persoal\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 8\n",
    "new_word = \"Axencia de Protección de Datos\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 11\n",
    "update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "\n",
    "item_idx = 12\n",
    "new_word = \"Torre de Cristal de A Coruña\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "# add new ne, if any\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281",
   "metadata": {},
   "source": [
    "##### Row idx 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 29\n",
    "email = df.iloc[row_idx]\n",
    "check_email_lang(email[\"file_name\"], email[\"lang\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne\n",
    "item_idx = 1\n",
    "new_word = \"Cristina Costas Varela\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "item_idx = 3\n",
    "new_word = \"CACTI\"\n",
    "update_ne_word(item_idx, new_word, ne_list)\n",
    "update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "\n",
    "# remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "# add new ne, if any\n",
    "insert_idx = 4\n",
    "sent_idx = 2\n",
    "n_word = \"Universidade de Vigo\"\n",
    "n_pseudonym = org_pseudo\n",
    "n_entity_group = org_group\n",
    "occurrence = 1\n",
    "add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "            eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "# continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update email in df\n",
    "df.at[row_idx, \"ne_list\"] = ne_list\n",
    "df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "# get new pseudo content\n",
    "updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update pseudo content in df\n",
    "df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated df to csv\n",
    "df.iloc[[row_idx]].to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290",
   "metadata": {},
   "source": [
    "##### Create final CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "csv_folder = Path(\"../../../data/\")\n",
    "csv_files = [csv_folder / f\"eval_data_200_eml_idx{i}.csv\" for i in range(len(chosen_files))]\n",
    "df_list = [pd.read_csv(csv_file) for csv_file in csv_files]\n",
    "checked_df = pd.concat(df_list, ignore_index=True)\n",
    "checked_df.to_csv(f\"../../../data/checked_eval_data_200_eml_{len(chosen_files)}_emails.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mailcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
