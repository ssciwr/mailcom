{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook for testing Corpus 200 emails\n",
    "*Scientific Software Center, University of Heidelberg, April 2025*\n",
    "\n",
    "The dataset `Corpus 200 emails` contains 200 multilingual emails (Spanish, English, and Portuguese/Galician) formatted in accordance with the RFC2822 specification. Download the dataset [here](https://figshare.com/articles/dataset/Corpus_200_Emails/1326662?file=1936502)\n",
    "\n",
    "This notebook will create an evaluation dataset for `mailcom` using 30 emails from `Corpus 200 emails` (10 emails per language).\n",
    "\n",
    "For each email in the dataset, we record:\n",
    "* email content\n",
    "* email language\n",
    "* detected dates in the email\n",
    "* list of named entities (NE)\n",
    "* pseudo content\n",
    "* list of sentences\n",
    "* list of sentences after email pseudonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark email numbers for languages\n",
    "# start with 1\n",
    "gl_emails = [\"01\", \"02\", \"03\", \"04\", 10, 12, 15]\n",
    "gl_files = [str(i) + \".eml\" for i in gl_emails]\n",
    "pt_emails = [30, 36, 66]\n",
    "pt_files = [str(i) + \".eml\" for i in pt_emails]\n",
    "es_emails = [\"05\", \"06\", \"07\", \"09\", 11, 23, 28, 31, 33, 34]\n",
    "es_files = [str(i) + \".eml\" for i in es_emails]\n",
    "en_emails = [13, 14, 19, 20, 22, 24, 32, 35, 37, 38]\n",
    "en_files = [str(i) + \".eml\" for i in en_emails]\n",
    "chosen_files = gl_files + pt_files + es_files + en_files\n",
    "assert len(set(chosen_files)) == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../../../eval_data_mailcom\"\n",
    "input_dir = \"../../../mailcom/test/data_extended/200_eml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_group = \"MISC\"\n",
    "misc_pseudo = \"[misc]\"\n",
    "org_group = \"ORG\"\n",
    "org_pseudo = \"[organization]\"\n",
    "loc_group = \"LOC\"\n",
    "loc_pseudo = \"[location]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Copy files (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run when needed!\n",
    "# copy files from source to input_dir\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "source_files = Path(source_dir).glob(\"*.eml\")\n",
    "for source_file in source_files:\n",
    "    if source_file.name in chosen_files:\n",
    "        shutil.copy(source_file, input_dir)\n",
    "        print(f\"Copied {source_file.name} to {input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Create a draft version of the dataset (run once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "First, we use the language detection, date detection, and pseunonymize from `mailcom` to buil the draft version of the dataset. Each email will be manually checked for validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate language detection\n",
    "new_settings = {\"default_lang\": \"\"}\n",
    "workflow_settings = mailcom.get_workflow_settings(new_settings=new_settings, \n",
    "                                                  save_updated_settings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files from input_dir\n",
    "input_handler = mailcom.get_input_handler(in_path=input_dir, in_type=\"dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the input data\n",
    "mailcom.process_data(input_handler.get_email_list(), workflow_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output to csv\n",
    "mailcom.write_output_data(input_handler, \"../../../data/eval_data_200_eml.csv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Manually check and modify each email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "##### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary functions\n",
    "\n",
    "import pandas as pd\n",
    "import mailcom\n",
    "from mailcom.parse import Pseudonymize\n",
    "\n",
    "\n",
    "# get workflow settings\n",
    "new_settings = {\"default_lang\": \"\"}\n",
    "workflow_settings = mailcom.get_workflow_settings(new_settings=new_settings, \n",
    "                                                  save_updated_settings=False)\n",
    "pseudonymizer = Pseudonymize(workflow_settings.get(\"pseudo_first_names\", {}))\n",
    "\n",
    "\n",
    "def print_email(email: dict):\n",
    "    print(\"file name:\", email[\"file_name\"])\n",
    "    print(\"= Email cleaned content =======\\n\", email[\"cleaned_content\"])\n",
    "    print(\"= Email language =======\\n\", email[\"lang\"])\n",
    "    print(\"= Detected dates =======\\n\", email[\"detected_datetime\"])\n",
    "    print(\"= NE list =======\")\n",
    "    for idx, (sent_idx, ne) in enumerate(zip(eval(email[\"ne_sent\"]), eval(email[\"ne_list\"]))):\n",
    "        print(f\"  {idx}- sentence {sent_idx}, {ne[\"word\"]} - {ne[\"entity_group\"]} - {ne[\"start\"]} - {ne[\"end\"]} - {ne[\"pseudonym\"]}\")\n",
    "    print(\"= Sentences =======\\n\")\n",
    "    for i, sent in enumerate(eval(email[\"sentences\"])):\n",
    "        print(f\"  {i}- {sent}\")\n",
    "    print(\"= Pseudo content =======\\n\", email[\"pseudo_content\"])\n",
    "\n",
    "\n",
    "def check_email_lang(file_name, lang) -> bool:\n",
    "    if file_name in gl_files and lang == \"gl\":\n",
    "        return True\n",
    "    elif file_name in pt_files and lang == \"pt\":\n",
    "        return True\n",
    "    elif file_name in es_files and lang == \"es\":\n",
    "        return True\n",
    "    elif file_name in en_files and lang == \"en\":\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Incorrect detected language for file:\", file_name)\n",
    "        return False\n",
    "\n",
    "\n",
    "def find_left_offset(old_word, new_word):\n",
    "    old_longer = len(old_word) > len(new_word)\n",
    "    # find old word in the new word\n",
    "    if old_longer:\n",
    "        start_offset = old_word.find(new_word)\n",
    "    else:\n",
    "        start_offset = new_word.find(old_word)\n",
    "\n",
    "    left_offset = start_offset if old_longer else - start_offset\n",
    "    return left_offset\n",
    "\n",
    "\n",
    "def update_ne_word(item_idx, new_word, ne_list):\n",
    "    old_word = ne_list[item_idx][\"word\"]\n",
    "    ne_list[item_idx][\"word\"] = new_word\n",
    "    l_offset = find_left_offset(old_word, ne_list[item_idx][\"word\"])\n",
    "    ne_list[item_idx][\"start\"] += l_offset\n",
    "    ne_list[item_idx][\"end\"] = ne_list[item_idx][\"start\"] + len(ne_list[item_idx][\"word\"])\n",
    "\n",
    "\n",
    "def update_ne_group(item_idx, new_group, new_pseudo, ne_list):\n",
    "    ne_list[item_idx][\"entity_group\"] = new_group\n",
    "    ne_list[item_idx][\"pseudonym\"] = new_pseudo\n",
    "\n",
    "\n",
    "def remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices):\n",
    "    new_ne_list = []\n",
    "    new_ne_sent = []\n",
    "    for idx, ne in enumerate(ne_list):\n",
    "        if idx in incorrect_ne_indices:\n",
    "            # remove the ne from the list\n",
    "            continue\n",
    "        else:\n",
    "            new_ne_list.append(ne)\n",
    "            new_ne_sent.append(ne_sent[idx])\n",
    "    return new_ne_list, new_ne_sent\n",
    "\n",
    "\n",
    "def find_nth_occurrence(sentence, word, occurrence):\n",
    "    import re\n",
    "    pattern = re.compile(re.escape(word))\n",
    "    matches = [m.start() for m in pattern.finditer(sentence)]\n",
    "    return matches[occurrence - 1] if len(matches) >= occurrence else -1\n",
    "\n",
    "\n",
    "def add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_e_group, sentence, ocurrence, ne_list, ne_sent):\n",
    "    new_ne = {\"entity_group\": n_e_group, \"word\": n_word, \"pseudonym\": n_pseudonym}\n",
    "    # important!\n",
    "    # indices are determined after email pseudonymization!\n",
    "    sentence = pseudonymizer.pseudonymize_email_addresses(sentence)\n",
    "    # find the start and end of the new ne\n",
    "    new_ne[\"start\"] = find_nth_occurrence(sentence, n_word, ocurrence)\n",
    "    new_ne[\"end\"] = new_ne[\"start\"] + len(new_ne[\"word\"])\n",
    "    ne_list.insert(insert_idx, new_ne)\n",
    "    ne_sent.insert(insert_idx, sent_idx)\n",
    "\n",
    "\n",
    "def get_new_pseudo_content(df, row_idx):\n",
    "    # get updated values\n",
    "    email = df.iloc[row_idx]\n",
    "\n",
    "    # get NE for each sentence in the email\n",
    "    ne_sent_dict = {}\n",
    "    for sent_idx, ne in zip(email[\"ne_sent\"], email[\"ne_list\"]):\n",
    "        if str(sent_idx) not in ne_sent_dict:\n",
    "            ne_sent_dict[str(sent_idx)] = []\n",
    "        ne_sent_dict[str(sent_idx)].append(ne)\n",
    "\n",
    "    # note. the indices of NE are only correct after the email is pseudonymized!\n",
    "    updated_pseudo_content = pseudonymizer.pseudonymize_with_updated_ne(eval(email[\"sentences_after_email\"]),\n",
    "                                                                        ne_sent_dict,\n",
    "                                                                        email[\"lang\"],\n",
    "                                                                        eval(email[\"detected_datetime\"]),\n",
    "                                                                        workflow_settings.get(\"pseudo_emailaddresses\", True),\n",
    "                                                                        workflow_settings.get(\"pseudo_ne\", True),\n",
    "                                                                        workflow_settings.get(\"pseudo_numbers\", True))\n",
    "    return updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark email indices that are already checked\n",
    "checked_rows = [0, 1, 2, 3, 4, 5]\n",
    "old_row_idx = None if not checked_rows else checked_rows[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output from last updated csv\n",
    "if old_row_idx is None:\n",
    "    # read the original csv\n",
    "    df = pd.read_csv(\"../../../data/eval_data_200_eml.csv\")\n",
    "else:\n",
    "    # read the updated csv\n",
    "    tmp_row_idx = old_row_idx\n",
    "    while tmp_row_idx >= 0:\n",
    "        try:\n",
    "            df = pd.read_csv(f\"../../../data/eval_data_200_eml_idx{tmp_row_idx}.csv\")\n",
    "            print(\"Read file:\", f\"../../../data/eval_data_200_eml_idx{tmp_row_idx}.csv\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            tmp_row_idx -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually check each email\n",
    "row_idx = old_row_idx + 1 if old_row_idx is not None else 0\n",
    "email = df.iloc[row_idx]\n",
    "if check_email_lang(email[\"file_name\"], email[\"lang\"]):\n",
    "    print(\"Correct detected language for file:\", email[\"file_name\"])\n",
    "else:\n",
    "    print(\"Incorrect detected language for file:\", email[\"file_name\"])\n",
    "print_email(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark incorrect indices of NE -- compared to the original\n",
    "incorrect_ne_indices = {}\n",
    "incorrect_ne_indices[\"0\"] = {\"u\": [2]}\n",
    "incorrect_ne_indices[\"1\"] = {\"u\": [4],\n",
    "                             \"r\": [7],\n",
    "                             \"a\": [2]} # the \"r\" and \"a\" cases are updated manually\n",
    "incorrect_ne_indices[\"2\"] = {\"u\": [2]}\n",
    "incorrect_ne_indices[\"3\"] = {\"u\": [1],\n",
    "                             \"r\": [3],\n",
    "                             \"a\": []}\n",
    "incorrect_ne_indices[\"4\"] = {\"u\": [6, 8, 9],\n",
    "                             \"r\": [10],\n",
    "                             \"a\": [6, 4, 5]}\n",
    "incorrect_ne_indices[\"5\"] = {\"u\": [9],\n",
    "                             \"r\": [],\n",
    "                             \"a\": []}\n",
    "incorrect_ne_indices[\"6\"] = {\"u\": [6],\n",
    "                             \"r\": [5],\n",
    "                             \"a\": []}\n",
    "incorrect_ne_indices[\"7\"] = {\"u\": [],\n",
    "                             \"r\": [10, 11],\n",
    "                             \"a\": [22]}\n",
    "incorrect_ne_indices[\"8\"] = {\"u\": [1, 4, 5, 6 ,7, 9, 10, 15, 20, 22, 27],\n",
    "                             \"r\": [23, 31],\n",
    "                             \"a\": [8],\n",
    "                             \"r-c\": [2, 3]}\n",
    "incorrect_ne_indices[\"9\"] = {\"u\": [17],\n",
    "                             \"r\": [],\n",
    "                             \"a\": [],\n",
    "                             \"r-c\": []}\n",
    "incorrect_ne_indices[\"10\"] = {\"u\": [1, 19],\n",
    "                              \"r\": [13, 20, 23],\n",
    "                              \"a\": [],\n",
    "                              \"r-c\": []}\n",
    "incorrect_ne_indices[\"11\"] = {\"u\": [6, 9, 11, 13, 18, 19, 21, 22, 23],\n",
    "                              \"a\": [26],\n",
    "                              \"r\": [25],\n",
    "                              \"a-c\": [22],\n",
    "                              \"r-c\": [20],\n",
    "                              \"a-c-c\": [12, 7],\n",
    "                              \"r-c-c\": [5],\n",
    "                              \"a-c-c-c\": [4, 2, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update incorrect ne manually, if any\n",
    "ne_list = eval(email[\"ne_list\"])\n",
    "ne_sent = eval(email[\"ne_sent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "##### Row idx 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 2\n",
    "    new_word = \"Galiza\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "    # add new ne, if any\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "##### Row idx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 4\n",
    "    new_word = \"Proxecto Fin de Carreira\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 2\n",
    "    sent_idx = 0\n",
    "    n_word = \"Sala de Xuntas\"\n",
    "    n_pseudonym = loc_pseudo\n",
    "    n_entity_group = loc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "##### Row idx 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 2\n",
    "    update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "    # add new ne, if any\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "##### Row idx 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 1\n",
    "    update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "##### Row idx 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 6\n",
    "    new_word = \"SPEA\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 8\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 9\n",
    "    new_word = \"SPEA2\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 6\n",
    "    sent_idx = 4\n",
    "    n_word = \"NSGAII\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "    \n",
    "    insert_idx = 4\n",
    "    sent_idx = 2\n",
    "    n_word = \"NSGAII\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "    \n",
    "    insert_idx = 5\n",
    "    sent_idx = 2\n",
    "    n_word = \"SPEA2\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "##### Row idx 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 9\n",
    "    new_word = \"Gabinete Juridico\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, loc_group, loc_pseudo, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "\n",
    "    # add new ne, if any\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "##### Row idx 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 1\n",
    "    new_word = \"Enxeñería Informática\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 4\n",
    "    new_word = \"Campus de Ourense\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 5\n",
    "    new_word = \"nasassocialmedia\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 6\n",
    "    new_word = \"Enxeñaría Informática\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 7\n",
    "    new_word = \"Enxeñaría Informática\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 9\n",
    "    new_word = \"nasassocialmedia\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 10\n",
    "    new_word = \"nasassocialmedia\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 15\n",
    "    new_word = \"Campus de Ourense\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 20\n",
    "    new_word = \"nasassocialmedia\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 22\n",
    "    new_word = \"nasassocialmedia\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 27\n",
    "    new_word = \"Edificio Politécnico\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 8\n",
    "    sent_idx = 3\n",
    "    n_word = \"LRU\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group, \n",
    "               eval(email[\"sentences\"])[sent_idx], 1, ne_list, ne_sent)\n",
    "\n",
    "    # continue removing, if any\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "##### Row idx 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 1\n",
    "    new_word = \"Expert Systems With Applications\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 19\n",
    "    new_word = \"OX5 1GB\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    \n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "\n",
    "    # continue removing, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "##### Row idx 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_idx = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update incorrect ne\n",
    "    item_idx = 6\n",
    "    new_word = \"eswa\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "\n",
    "    item_idx = 9\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 11\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 13\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 18\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 19\n",
    "    new_word = \"Scopus\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 21\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 22\n",
    "    new_word = \"Scopus\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, misc_group, misc_pseudo, ne_list)\n",
    "\n",
    "    item_idx = 23\n",
    "    new_word = \"elsevier\"\n",
    "    update_ne_word(item_idx, new_word, ne_list)\n",
    "    update_ne_group(item_idx, org_group, org_pseudo, ne_list)\n",
    "    \n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 26\n",
    "    sent_idx = 21\n",
    "    n_word = \"Expert Systems With Applications\"\n",
    "    n_pseudonym = org_pseudo\n",
    "    n_entity_group = org_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 22\n",
    "    sent_idx = 18\n",
    "    n_word = \"EES\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 2\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 12\n",
    "    sent_idx = 12\n",
    "    n_word = \"EES\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "    \n",
    "    # add new ne, if any\n",
    "    insert_idx = 7\n",
    "    sent_idx = 6\n",
    "    n_word = \"ees\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 2\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    # remove incorrect indices from ne_list and ne_sent of email\n",
    "    ne_list, ne_sent = remove_incorrect_ne_indices(ne_list, ne_sent, incorrect_ne_indices[str(row_idx)][\"r-c-c\"])\n",
    "\n",
    "    # add new ne, if any\n",
    "    insert_idx = 4\n",
    "    sent_idx = 6\n",
    "    n_word = \"ees\"\n",
    "    n_pseudonym = misc_pseudo\n",
    "    n_entity_group = misc_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "\n",
    "    insert_idx = 2\n",
    "    sent_idx = 3\n",
    "    n_word = \"Expert Systems With Applications\"\n",
    "    n_pseudonym = org_pseudo\n",
    "    n_entity_group = org_group\n",
    "    occurrence = 2\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)\n",
    "    \n",
    "    insert_idx = 1\n",
    "    sent_idx = 3\n",
    "    n_word = \"Expert Systems With Applications\"\n",
    "    n_pseudonym = org_pseudo\n",
    "    n_entity_group = org_group\n",
    "    occurrence = 1\n",
    "    add_new_ne(insert_idx, sent_idx, n_word, n_pseudonym, n_entity_group,\n",
    "               eval(email[\"sentences\"])[sent_idx], occurrence, ne_list, ne_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update email in df\n",
    "    df.at[row_idx, \"ne_list\"] = ne_list\n",
    "    df.at[row_idx, \"ne_sent\"] = ne_sent\n",
    "\n",
    "    # get new pseudo content\n",
    "    updated_pseudo_content = get_new_pseudo_content(df, row_idx)\n",
    "updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # update pseudo content in df\n",
    "    df.at[row_idx, \"pseudo_content\"] = updated_pseudo_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other updates, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check df using data wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if row_idx == considered_idx:\n",
    "    # save updated df to csv\n",
    "    df.to_csv(f\"../../../data/eval_data_200_eml_idx{row_idx}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mailcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
